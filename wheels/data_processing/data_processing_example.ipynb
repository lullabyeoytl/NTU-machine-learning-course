{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"楷体\">\n",
    "Create  data set & local environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first download data\n",
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    if not os.path.isdir(housing_path):\n",
    "        os.makedirs(housing_path)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()\n",
    "\n",
    "fetch_housing_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def load_housing_data(housing_path = HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path,\"housing.csv\")\n",
    "    return pd.read_csv(csv_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"楷体\">\n",
    " data spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data spliting\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "def split_train_test(data,test_ratio):\n",
    "    shuffled_indices = np.random.permutation((len(data)))\n",
    "    test_set_size = int(len(data)*test_ratio)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_indices:]\n",
    "    return data.iloc[train_indices], data.iloc[test_indices]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "<font face=\"楷体\">\n",
    "大部分的机器学习算法无法在缺失的特征上工作，所以我们要创建一些函数来辅助它。\n",
    "\n",
    "前面我们已经注意到total_bedrooms属性有部分值缺失，所以我们要解决它。有以下三种选择：\n",
    "- 1.放弃这些相应的区域。\n",
    "- 2.放弃整个属性。\n",
    "- 3.将缺失的值设置为某个值（0、平均数或者中位数等）。\n",
    "\n",
    "通过DataFrame的dropna（）、drop（）和fillna（）方法，可以轻松完成这些操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validation in sklearn\n",
    "<font face=\"楷体\">\n",
    "在数据集和估计器上应用交叉验证最简单的方法是调用cross_val_score帮助函数。\n",
    "```python\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1)     # *model you select*\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "```\n",
    "all method can be seen in this link below:\n",
    "\n",
    "https://scikit-learn.org.cn/view/6.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 微调模型（调参）\n",
    "\n",
    "事实上scikit-learn中有现成的库替人搜索，只需要告诉实验的超参数是什么就OK\n",
    "\n",
    "以字典的形式告诉；\n",
    "\n",
    "GridSearchCV：会使用交叉验证来评估超参数值的所有可能组合。例如，\n",
    "下面这段代码搜索RandomForestRegressor的超参数值的最佳组合：\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = [\n",
    "{'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "{'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "]\n",
    "# 这个param_grid包含了两类，一类是bootstrap为true（default），一类是false，两类用大括号隔开\n",
    "forest_reg = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "scoring='neg_mean_squared_error',\n",
    "return_train_score=True)\n",
    "grid_search.fit(housing_prepared, housing_labels)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当你不知道超参数应该赋什么值时，一个简单的方法是尝试\n",
    "10的连续幂次方\n",
    "\n",
    "（如果你想要得到更细粒度的搜索，可以使用更小的\n",
    "数，参考这个示例中所示的n_estimators超参数）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 随机搜索\n",
    "当超参数的搜索范围较大时，通常会优先选择\n",
    "使用RandomizedSearchCV。\n",
    "\n",
    "这个类用起来与GridSearchCV类大致相\n",
    "同，但它不会尝试所有可能的组合，而是在每次迭代中为每个超参数\n",
    "选择一个随机值，然后对一定数量的随机组合进行评估。\n",
    "\n",
    "这种方法有两个显著好处：\n",
    "- 如果运行随机搜索1000个迭代，那么将会探索每个超参数的\n",
    "1000个不同的值（而不是像网格搜索方法那样每个超参数仅探索少量\n",
    "几个值）。\n",
    "- 通过简单地设置迭代次数，可以更好地控制要分配给超参数搜\n",
    "索的计算预算。\n",
    "\n",
    "attribute and methods are seen in this link: *https://scikit-learn.org.cn/view/658.html*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save your MODEL\n",
    "\n",
    "go to see the professional doc for joblib"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
