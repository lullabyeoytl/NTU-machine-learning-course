{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "# fake code:\n",
    "   repeat R times:<br>\n",
    "       calculate whole<br>\n",
    "       use alpha*gradient to update w<br>\n",
    "       return w \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here comes the situation that we have 100 datas ,each data has 2 features(x1,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math as exp\n",
    "import numpy as np \n",
    "def loadData():\n",
    "    dataMat = []  \n",
    "    labelMat = []\n",
    "    fr = open('testSet.dat')\n",
    "    for line in fr.readlines():\n",
    "        lineArr = line.strip().split()\n",
    "        dataMat.append([1.0,float(lineArr[0]),float(lineArr[1])])\n",
    "        labelMat.append(int(lineArr[2]))\n",
    "    return dataMat,labelMat\n",
    "\n",
    "def sigmoid(inX):\n",
    "    return 1.0/(1+exp(-inX))\n",
    "\n",
    "def gradAscent(dataMatIn, classLabels):\n",
    "    datdMatrix = np.mat(dataMatIn)\n",
    "    labelMat = np.mat(classLabels).transpose()\n",
    "    m,n = np.shape(datdMatrix)\n",
    "    alpha = 0.1 #normal alpha\n",
    "    maxCycles = 500\n",
    "    weights = np.ones((n,1)) #initilize\n",
    "    for k in range(maxCycles):\n",
    "        h = sigmoid(datdMatrix*weights)\n",
    "        error = labelMat - h # every column minus h\n",
    "        weights = weights + alpha*datdMatrix.transpose()*error #update\n",
    "    return weights\n",
    "\n",
    "#draw the picture\n",
    "def plotBestFit(wei):\n",
    "    import matplotlib.pyplot as plt\n",
    "    weights = wei.getA()\n",
    "    '''\n",
    "    Return self as an ndarray object. Equivalent to np.asarray(self).\n",
    "    '''\n",
    "    dataMat,labelMat = loadData()\n",
    "    dataArr = np.array(dataMat)\n",
    "    n =np.shape(dataArr)[0]\n",
    "    xcord1 = []\n",
    "    ycord1 = []\n",
    "    xcord2 = []\n",
    "    ycord2 = []\n",
    "    for i in range(n):\n",
    "        if int(labelMat[i]) == 1:\n",
    "            xcord1.append(dataArr[i,1]); ycord1.append(dataArr[i,2])\n",
    "        else:\n",
    "            xcord2.append(dataArr[i,1]); ycord2.append(dataArr[i,2])\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111) #大致意思就是输入 三位数字，abc，根据abc将原图划分成a行，b列。那么就会将原图划分成a*b个子图，然后c就是我们的下标。我们通过c来指定展示我们要的子图。\n",
    "    ax.scatter(xcord1,ycord1,s=30,c='red',marker='s')\n",
    "    ax.scatter(xcord2,ycord2,s=30,c='green')\n",
    "    x = np.arange(-3.0,3.0,0.3)\n",
    "    y =(-weights[0]-weights[1]*x)/weights[2]\n",
    "    ax.plot(x,y)\n",
    "    plt.xlabel('X1');plt.ylabel('X2')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "dataArr,LabelMat = loadData()\n",
    "gradAscent(dataArr,LabelMat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ''' np.ones()\n",
    "\n",
    "Parameters\n",
    "\n",
    "shape : int or sequence of ints\n",
    "\n",
    "    Shape of the new array, e.g., (2, 3) or 2.\n",
    "\n",
    "dtype : data-type, optional\n",
    "\n",
    "    The desired data-type for the array, e.g., numpy.int8. Default is numpy.float64.\n",
    "\n",
    "order : {'C', 'F'}, optional, default: C\n",
    "\n",
    "    Whether to store multi-dimensional data in row-major (C-style) or column-major (Fortran-style) order in memory.\n",
    "\n",
    "Returns\n",
    "\n",
    "out : ndarray\n",
    "\n",
    "    Array of ones with the given shape, dtype, and order.\n",
    "\n",
    "Examples\n",
    "\n",
    ">>> np.ones(5)\n",
    "\n",
    "array([1., 1., 1., 1., 1.])\n",
    "\n",
    ">>> np.ones((5,), dtype=int)\n",
    "\n",
    "array([1, 1, 1, 1, 1])\n",
    "\n",
    ">>> np.ones((2, 1))\n",
    "\n",
    "array([[1.],\n",
    "       [1.]])\n",
    "\n",
    ">>> s = (2,2)\n",
    "\n",
    ">>> np.ones(s)\n",
    "\n",
    "array([[1.,  1.],\n",
    "       [1.,  1.]])\n",
    "\n",
    "    ''' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random grad_descent\n",
    "\n",
    "notice how the use of sigmond change and the change of w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stocGradAscent1(dataMatrix, classLabels, numIter=150):\n",
    "    m,n = np.shape(dataMatrix)\n",
    "    weights = np.ones(n)   #initialize to all ones\n",
    "    for j in range(numIter):\n",
    "        dataIndex = range(m)\n",
    "        for i in range(m):\n",
    "            alpha = 4/(1.0+j+i)+0.0001    #apha decreases with iteration, does not \n",
    "            randIndex = int(np.random.uniform(0,len(dataIndex)))#go to 0 because of the constant\n",
    "            h = sigmoid(sum(dataMatrix[randIndex]*weights))\n",
    "            error = classLabels[randIndex] - h\n",
    "            weights = weights + alpha * error * dataMatrix[randIndex]\n",
    "            del(dataIndex[randIndex])\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# true example\n",
    "\n",
    "now we got true example concerning classify. we choose to classify by logistic ,p over 0.5 return 1.0,below 0.5 return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyVector(inX, weights):\n",
    "    prob = sigmoid(sum(inX*weights))\n",
    "    if prob > 0.5: return 1.0\n",
    "    else: return 0.0\n",
    "\n",
    "def colicTest():\n",
    "    frTrain = open('horseColicTraining.txt'); frTest = open('horseColicTest.txt')\n",
    "    trainingSet = []; trainingLabels = []\n",
    "    for line in frTrain.readlines():\n",
    "        currLine = line.strip().split('\\t')\n",
    "        lineArr =[]\n",
    "        for i in range(21):\n",
    "            lineArr.append(float(currLine[i]))\n",
    "        trainingSet.append(lineArr)\n",
    "        trainingLabels.append(float(currLine[21]))\n",
    "    trainWeights = stocGradAscent1(np.array(trainingSet), trainingLabels, 1000)\n",
    "    errorCount = 0; numTestVec = 0.0\n",
    "    for line in frTest.readlines():\n",
    "        numTestVec += 1.0\n",
    "        currLine = line.strip().split('\\t')\n",
    "        lineArr =[]\n",
    "        for i in range(21):\n",
    "            lineArr.append(float(currLine[i]))\n",
    "        if int(classifyVector(np.array(lineArr), trainWeights))!= int(currLine[21]):\n",
    "            errorCount += 1\n",
    "    errorRate = (float(errorCount)/numTestVec)\n",
    "    print (\"the error rate of this test is: %f\" % errorRate)\n",
    "    return errorRate\n",
    "\n",
    "def multiTest():\n",
    "    numTests = 10; errorSum=0.0\n",
    "    for k in range(numTests):\n",
    "        errorSum += colicTest()\n",
    "    print (\"after %d iterations the average error rate is: %f\" % (numTests, errorSum/float(numTests)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression in skicit-learn\n",
    "doc location:https://scikit-learn.org.cn/view/378.html\n",
    "\n",
    "sklearn.linear_model.LogisticRegression\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
